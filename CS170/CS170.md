
Lecture 1 - Introduction

When we talk about runtime, we always talk about worst case. In other classes, you will learn about average cases.

In asymptotics, we only care about the behavior of large 
- ignore constants and focus on the largest dependence on n.

O(n) - "order of n"

How fast is grade school integer multiplcation?
=> O(n^2) + O(n) => O(n^2)
- we ignore lower dependences of n

Can we do better than O(n) for addition?
=> No, it takes at least n steps to just read the numbers

Can we do better than O(n^2) for multiplication?
=> Egyptian multiplication

![[Pasted image 20250204183914.png]]

Not actually faster!

There are ways to do better for multiplication:
- Karatsuba: O(n^1.6)
- Toom-3/Toom-Cook: O(n^1.465)
- Harvey and van der Hoeven: O(nlog(n))


**Divide and Conquer**
Breaking up a big problem into smaller subproblems. If I don't know a problem, if I keep breaking it down, eventually I'll get a problem I can do.

**Lecture 6 - Directed Graphs**

```
DFS(G)
	boolean array visited[n] <- false 
	for all v
		if visited[v] == false
			Explore(G, v)
```
```
Explore(G, u)
	visited[u] = true

	for v in (u,v) { E
		if visited[v] == false
			Explore(G, v)
```

Back edges - a edge that has already been visited (v, u)
Forward edges - a edge that has already been visited (u, v)
Tree edges - occurs in the recursive tree and first time visit

We want to be able to detect these types of edges in our algorithm

```
DFS(G)
	boolean array visited[n] <- false
	**clock = 1**
	**int array pre[n], post[n]** 
	
	for all v
		if visited[v] == false
			Explore(G, v)
```
```
Explore(G, u)
	visited[u] = true
	**pre[u] = clock**
	**clock += 1**

	for v in (u,v) { E
		if visited[v] == false
			Explore(G, v)
	**post[u] = clock**
	**clock += 1**
```