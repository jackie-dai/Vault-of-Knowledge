
Why do we ignore smaller values?
- Constants depend on the platform and computer
- Easier to compare the performance of algorithms on large inputs


T(n) is O(g(n)) if and only if there exists a constant c and n_0
such that all n is greater than n_0, T(n) is upper bounded by c * g(n)

T(n) <= O(g(n))


dx T(n) <= dx g(n)



